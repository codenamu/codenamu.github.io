---
layout: post
status: publish
published: true
title: "[춘식이의 코드이야기] 10분만에 따라하는 웹사이트 긁어오기"
author:
  display_name: thechunsik
  login: thechunsik
  email: thechunsik@gmail.com
  url: http://chunsik.org
author_login: thechunsik
author_email: thechunsik@gmail.com
author_url: http://chunsik.org
wordpress_id: 16385
wordpress_url: http://codenamu.org/?p=16385
date: '2014-11-13 17:54:18 +0900'
date_gmt: '2014-11-13 08:54:18 +0900'
categories:
- "춘식이의 코드이야기"
tags: []
comments:
- id: 100
  author: "[춘식이의 코드이야기] 10분만에 따라하는 웹사이트 긁어오기 | 해인나라"
  author_email: ''
  author_url: http://ec2-54-64-188-153.ap-northeast-1.compute.amazonaws.com/wordpress/?p=792
  date: '2015-02-17 16:52:27 +0900'
  date_gmt: '2015-02-17 07:52:27 +0900'
  content: "[&#8230;] [춘식이의 코드이야기] 10분만에 따라하는 웹사이트 긁어오기. [&#8230;]"
- id: 101
  author: "[춘식이의 코드이야기] 10분만에 따라하는 웹사이트 긁어오기 | HackSon(dot)Net Blog"
  author_email: ''
  author_url: http://hackson.net/?p=39
  date: '2015-03-24 21:57:32 +0900'
  date_gmt: '2015-03-24 12:57:32 +0900'
  content: "[&#8230;] http://codenamu.org/2014/11/13/16385/ [&#8230;]"
- id: 103
  author: htmlshark
  author_email: htmlshark9@gmail.com
  author_url: ''
  date: '2015-04-13 14:09:00 +0900'
  date_gmt: '2015-04-13 05:09:00 +0900'
  content: "그누보드와 XE로 사이트를 만들었는데 컨텐츠가 부족하신가요?\n\nhttp://www.htmlshark.ga  도와 드립니다.\n\n범용
    웹 파싱 툴 \n\n- 정상적인 네트워크 상황에서 시간당 15,000개 내외의 주소를 파싱\n\n- 게시물 제목 및 이미지 주소 필터링\n\n-
    입력 데이타베이스(그누보드, XE) 자동 탐지 및 게시판 테이블/모듈/분류 자동 인식\n\n- 게시물 작성자 및 조회수 랜덤 입력 기능\n\n-
    출처 표시 가능\n\n- 텍스트 파싱 모드 추가 (ver 1.1)\n\n- 페이지 추출 후 입력 기능 추가 (ver 1.1)\n\n- 지속적인
    업데이트"
- id: 104
  author: "민병철"
  author_email: minbang190@gmail.com
  author_url: ''
  date: '2015-05-14 10:39:00 +0900'
  date_gmt: '2015-05-14 01:39:00 +0900'
  content: "감사합니다. 웹 크롤링에 대해 짧고 쉽게 이야기 적어주셔서 잘 봤습니다. \n서로 의사소통 부분 언급해주신 것도 평소 생각과
    겹쳐 반가웠고요!"
- id: 107
  author: "천나겸"
  author_email: khellantz@naver.com
  author_url: ''
  date: '2015-07-14 14:00:00 +0900'
  date_gmt: '2015-07-14 05:00:00 +0900'
  content: hello I'm studying crawling with javascript but I don't have enough information
    about javascript.. how can i use this source code on html? please comment on Korean
    because I'm a Korean but can't typing Korean..
- id: 108
  author: BananaMilk
  author_email: jgs1575@hanmail.net
  author_url: ''
  date: '2015-07-21 17:41:00 +0900'
  date_gmt: '2015-07-21 08:41:00 +0900'
  content: "웹크롤러를 이용해서 프로젝트를 하려고 합니다. 웹크롤러를 구현할 때 오픈소스 scrapy를 이용하는 방법, 지금 위에 글에서
    설명해주신 python을 통한 html 가져와서 하는 방법이 있는 것 같은데 어떤 방법이 더 효율적인지 궁금합니다. 답변 부탁드립니다. ^^"
- id: 109
  author: "김광민"
  author_email: kim25444@naver.com
  author_url: ''
  date: '2015-08-22 02:16:00 +0900'
  date_gmt: '2015-08-21 17:16:00 +0900'
  content: "웹 쪽에 관해서는 전혀 몰랐는데 갑자기 크롤링이 필요해서 이 글을 찾게 되었습니다. 여러모로 도움이 되었습니다. 감사합니다.
    ^^"
- id: 111
  author: SeungWoo Baek
  author_email: starclover@gmail.com
  author_url: http://spacechild.kr
  date: '2015-11-19 15:52:00 +0900'
  date_gmt: '2015-11-19 06:52:00 +0900'
  content: "재밌게 잘 읽었습니다. 궁금한 것이 있습니다. 이렇게 크롤링 코드를 짜놓고 나서, 대상 사이트의 html 구조가 바뀌면, 새로
    대응해서 크롤링 코드도 수정해야 하나요?"
- id: 112
  author: "춘식"
  author_email: thechunsik@gmail.com
  author_url: http://chunsik.org/
  date: '2015-11-22 00:45:00 +0900'
  date_gmt: '2015-11-21 15:45:00 +0900'
  content: |-
    안녕하세요! 재밌게 잘 읽어주셔서 감사합니다 :) 크롤링을 하려는 사이트 주소가 바뀌지 않았다면 크롤링 하고 나서 DOM을 찾을 때 선택하는 선택자만 바뀐 html 구조에 맞게 바꿔주시면 코드를 크게 바꿀 필요는 없을거에요 ^^



    현재 위 글에는 인코딩 문제를 포함해서 소소하게 빠진 내용들이 있어서 새로 글을 써야 하는데 아직 업데이트를 못했네요 ㅜ 새로 모듈을 만들어보고 있는데 완성되면 한번 업데이트 하도록 하겠습니다~!
- id: 113
  author: "춘식"
  author_email: thechunsik@gmail.com
  author_url: http://chunsik.org/
  date: '2015-11-22 00:45:00 +0900'
  date_gmt: '2015-11-21 15:45:00 +0900'
  content: "현재 위 글에는 인코딩 문제를 포함해서 소소하게 빠진 내용들이 있어서 새로 글을 써야 하는데 아직 업데이트를 못했네요 ㅜ 새로
    모듈을 만들어보고 있는데 완성되면 한번 업데이트 하도록 하겠습니다~!"
- id: 114
  author: "춘식"
  author_email: thechunsik@gmail.com
  author_url: http://chunsik.org/
  date: '2015-11-22 00:46:00 +0900'
  date_gmt: '2015-11-21 15:46:00 +0900'
  content: "아이고 벌써 네달 전 답변이라 무의미할 것 같지만 ㅜㅜ 보통 스크레이핑, 크롤링을 포함해서 데이터를 다루는 쪽으로는 파이썬이
    확실히 편리한 것 같은 것이 제 의견입니다 . 하지만 뭐 결국 목적만 같으면 수단은 다양해서 나쁠 것 없지 않을까요? node를 주로 쓰다보니
    node로 긁어오는 방법을 소개한 것 뿐이에요! 본인이 편하신 도구를 사용하는것이 최고인 것 같습니다."
- id: 115
  author: "춘식"
  author_email: thechunsik@gmail.com
  author_url: http://chunsik.org/
  date: '2015-11-22 00:47:00 +0900'
  date_gmt: '2015-11-21 15:47:00 +0900'
  content: "잘 봤다니 다행이네요 벌써 6개월 전이지만 ㅜ 현재 위 글에는 인코딩 문제를 포함해서 소소하게 빠진 내용들이 있어서 새로 글을
    써야 하는데 아직 업데이트를 못했네요 ㅜ 새로 모듈을 만들어보고 있는데 완성되면 한번 업데이트 하도록 하겠습니다~!"
- id: 116
  author: Song Jae Hoon
  author_email: wogns9704@naver.com
  author_url: ''
  date: '2015-12-01 23:18:00 +0900'
  date_gmt: '2015-12-01 14:18:00 +0900'
  content: "정말 잘 읽었습니다. 허나 페이지 중에서 asp나 자바스크립트로 이루어진, 예를들어 소스보기해서 원하는 값들이 없는 경우는 파싱을
    못하는 건가요"
- id: 117
  author: "춘식"
  author_email: thechunsik@gmail.com
  author_url: http://chunsik.org/
  date: '2016-01-06 18:33:00 +0900'
  date_gmt: '2016-01-06 09:33:00 +0900'
  content: "원하는 값들이 없는 경우가 어떤걸 말씀하시는 건가요? 페이지를 html이 아니라 해당 url 안에서 다른 url을 불러와서 컨텐츠를
    로딩하는 방식을 말씀하시는 것 같은데 그런 경우는 그 컨텐츠를 불러오는 url을 개발자 도구 안에서 네트워크 란을 참조해서 알아내야 합니다
    ^^ 그 url을 통해 긁어오면 되구요 ^^"
---
<p>데이터를 활용하여 유용한 서비스 및 어플리케이션을 만드는 사례들이 늘어가고 있다. 이 때 원하는 공공데이터 혹은 일반 오픈 데이터를 찾지 못하는 경우 웹사이트를 그대로 가져와서 직접 처리하는 경우를 많이 볼 수 있다. 이런 방법을 크롤링(Crawling) 혹은 스크래이핑(Scraping)이라고 한다. 아마 크롤링이나 크롤러는 많이 들어보셨을 듯! 대표적으로 <a href="http://popong.com" title="팀포퐁" target="_blank">팀포퐁</a>에서는 직접 <a href="https://github.com/teampopong/crawlers" title="파이썬을 이용한 크롤러" target="_blank">파이썬을 이용한 크롤러</a>를 만들어서 각종 정치 데이터를 가공한다. 가공한 데이터를 API 형태로 공개도 하고있다. 팀포퐁의 강철님께서는 파이썬 코리아 컨퍼런스 행사에서 '<a href="https://gist.github.com/cornchz/0ec0c3f5ca69bac2b625" title="30분만에 따라하는 동시성 스크래이퍼" target="_blank">30분만에 따라하는 동시성 스크래이퍼</a>'라는 주제로 발표한 적도 있다.</p>
<p>30분만에 동시성 스크래이퍼를 따라한다면 단순한 스크래이핑은 10분만에 가능하지 않을까? 꼭 스크래이핑은 파이썬으로만 해야할까? 그래서 준비했다. 자바스크립트를 활용한 '10만에 따라하는 HTML 긁어오기'. 굳이 10분만에 따라할 수 있는 것은 HTML을 가져오기 위한 가장 기본적인 기능만을 만들어볼 것이다. 그리고 숙련된 개발자보다 이제 웹개발에 관심을 갖게된 분들에게 스크래이핑을 소개하는 차원에서 쓰는 예제이다. 마지막으로 개발자들이 자꾸 크롤러, 스크래이퍼 거릴 때 답답해하던 기획자와 디자이너 분들을 위해 기본적인 원리를 이해할 수 있도록 준비해보았다.</p>
<h1>필요한 도구: <a title="request" href="https://github.com/request/request" target="_blank">request</a>, <a title="" target="_blank">cheerio</a></h1>
<p><code>request</code>는 우리가 브라우저에서 주소창에 원하는 주소를 치고 홈페이지를 들어가듯, 원하는 웹사이트의 html을 불러와주는 도구이다. <code>cheerio</code>는 핵심 기능만 간단히 설명하면 HTML은 구조적인 태그들의 집합으로 볼 수 있는데 이 때 원하는 요소(태그 혹은 속성)에 쉽게 접근할 수 있도록 도와주는 도구이다(<del datetime="2014-11-13T06:55:38+00:00">이번 예제에서는 DOM에 대한 자세한 이야기는 생략</del>). 핵심 내용은 <code>request</code>를 이용해서 내가 긁어오길 원하는 페이지의 URL을 이용하여 HTML 소스를 불러온 다음 <code>cheerio</code>를 이용하여 원하는 데이터를 가공하는 방식이다. 이번 예제에서는 <a href="http://codenamu.org/blog" title="코드나무 블로그" href="_blank">코드나무 블로그</a> 페이지를 불러와서 각 글마다 정리된 '제목', '포스트주소', '요약 내용', '카테고리' 세 가지 요소를 불러와본다.</p>
<h1><code>request</code>를 이용하여 HTML 가져오기</h1>
<p><iframe width="100%" height="265" src="http://jsfiddle.net/thechunsik/tdz8ukdg/2/embedded/" allowfullscreen="allowfullscreen" frameborder="0"></iframe><br />
<i>코드나무 블로그 HTML을 불러와서 변수 <code>$</code>에 <code>cheerio</code>를 이용해 담았다.</i></p>
<p>request에 필요한 요소는 내가 데이터를 가져오고자 하는 웹사이트의 URL 주소이다. 그래서 <code>url</code> 변수에 "http://codenamu.org/blog" 주소를 담았다. <code>request</code> 함수의 기본 사용 방법은 다음과 같다.</p>
<pre>
request(URL, function (err, response, html) {
    // URL로부터 가져온 페이지 소스가 html이란 변수에 담긴다.
})
</pre>
<p>이렇게 가져온 소스코드를 <code>cheerio</code>를 이용해서 주로 jQuery 변수에 사용하는 <code>$</code>에 담는다.</p>
<h1>블로그 제목 가져오기</h1>
<p><iframe width="100%" height="410" src="http://jsfiddle.net/thechunsik/tdz8ukdg/5/embedded/" allowfullscreen="allowfullscreen" frameborder="0"></iframe><br />
<i>블로그 제목 정보가 담긴 데이터를 반복해서 가져와 별도로 만든 <code>post</code> 변수에 담았다.</i></p>
<p>이제 본격적으로 불러온 웹사이트에서 원하는 정보를 탐색해보자. 우선 원하는 정보가 담겨져 있는 HTML 구조를 파악해야 한다. 코드나무 블로그를 들어가서 HTML 구조를 살펴보자.</p>
<p><a href="http://codenamu.org/wp-content/uploads/2014/11/inspector_in_codenamu_blog.png"><img src="http://codenamu.org/wp-content/uploads/2014/11/inspector_in_codenamu_blog.png" alt="코드나무 블로그 HTML 구조 살펴보기" width="100%" class="aligncenter size-full wp-image-16347" /></a></p>
<p>사진 속 화면은 <a href="http://www.mozilla.org/firefox/developer/" target="_blank">파이어폭스 개발자 에디션</a>(참조: <a href="http://hacks.mozilla.or.kr/2014/11/mozilla-introduces-the-first-browser-built-for-developers-firefox-developer-edition/" title="모질라가 만든 개발자를 위한 첫 브라우저: 파이어폭스 개발자 에디션" target="_blank">모질라가 만든 개발자를 위한 첫 브라우저: 파이어폭스 개발자 에디션</a>) 브라우저의 'Inspector' 기능('cmd + alt + c')을 사용하여 HTML 구조를 살펴보는 모습이다.</p>
<p>
현재 코드나무 블로그 웹사이트의 구조는 다음과 같다.</p>
<ul>
<li>각 포스트는 <code>&lt;div id="포스트번호" class="post ...."&gt; &lt;/div&gt;</code> 구조로 둘러쌓여 있다.</li>
<li>포스트 제목은 위 <code>&lt;h2 class="entry-title"&gt;  &lt;a&gt; href="포스트 주소"&gt;제목&lt;/a&gt;&lt;/h2&gt;</code>으로 담겨있다.
<li>포스트 요약은 <code>&lt;div class="entry-summary"&gt;&lt;p&gt;요약 내용&lt;/p&gt;&lt;/div&gt;</code>으로 담겨 있다.
<li>포스트 카테고리는 <code>&lt;div class="entry-meta entry-footer"&gt;&lt;span class="entry-categories"&gt;&lt;a&gt;카테고리1&lt;/a&gt;&lt;a&gt;카테고리2&lt;/a&gt; &lt;/span&gt; &lt;/div&gt;</code>으로 담겨있다.
</ul></p>
<p>자 이제 제목을 가져와보자. <code>cheerio</code>를 이용해서 웹사이트 HTML을 변수 <code>$</code>에 담았었다. 이제 원하는 제목 정보가 담긴 태그(<code>'.entry-title > a'</code>)를 변수 <code>$</code>를 이용해서 검색한다. 검색된 데이터를 변수 <code>data</code>에 담은 뒤 (<code>data = $(this);</code>) 제목(<code>data.text()</code>)과 포스트 주소(<code>data.attr('href')</code>)를 처리한다.</p>
<pre>
//원하는 태그를 이용해서 데이터를 가져오는데 데이터가 여러 개일 경우 .each 등을 이용하여 반복해서 가져오게 된다.
$('원하는 태그').each(function () {

})
</pre>
<p><i><code>cheerio</code> 활용하기</i></p>
<h1>나머지 요약 정보와 카테고리 가져오기</h1>
<p><iframe width="100%" height="600" src="http://jsfiddle.net/thechunsik/tdz8ukdg/4/embedded/" allowfullscreen="allowfullscreen" frameborder="0"></iframe><br />
<i>이어서 제목과 카테고리 정보를 가져왔다.</i></p>
<p>같은 방식으로 요약정보도 가져와보자. 요약 정보가 담긴 태그는 <code>'.entry-summary > p'</code>이다. 다음은 카테고리를 가져올 차례인데 카테고리는 이전 두 요소와는 다르게 한 포스트에 여러 개가 포함돼 있다. 이것을 해결해보자. 우선 모든 카테고리를 둘러싸고 있는 <code>'.entry-categories'</code> 태그를 가진 <code>span</code> 데이터를 불러온다. 그 다음 똑같은 방식으로 <code>span</code> 내에 포함된 모든 카테고리 요소: 카테고리1, 카테고리2를 반복문을 활용해서 다음과 같이 불러온다.</p>
<pre>
$(this).children('a').each(function(){

})
</pre>
<p>이렇게 되면 카테고리 갯수가 n개라면 n번 반복문을 돌면서 카테고리1, 카테고리2,,, 카테고리n 순서대로 반복해서 불러오게 된다.</p>
<h1>완성!</h1>
<p><script src="https://gist.github.com/thechunsik/7d479e8d1fa55d504d63.js"></script></p>
<p>완성된 소스코드에는 몇 가지가 추가된 것을 볼 수 있다. 데이터를 단순히 가져오는 것 뿐만 아니라 활용하기 위해서는 구조적인 형태로 가공해야할 필요가 있다. 완성된 소스코드에는 변수 <code>blog</code>에 빈 배열을 우선 담았다. 그 다음 매 포스트를 <code>post</code> 변수에 다음과 같은 구조의 <code>json</code>으로 만들어 <code>blog</code>에 순차적으로 담아보았다.</p>
<pre>
var post = {
    "title": "제목",
    "link": "포스트 주소",
    "summary": "요약 내용",
    "category": "카테고리 목록"
} 
</pre>
<h1>크롤러? 스크래이퍼? 쫄지마!</h1>
<p>강철님께서 이미 공유해주신 파이썬을 활용한 강력한 예제가 있기 때문에 내가 좋아하는 자바스크립트를 활용해서 예제를 짜보았다. 위에 언급했듯이 개발이 익숙한 개발자분들 보다 기획자, 디자이너 분들도 이제는 개발자와 대화하면서 좀 더 이해의 폭이 넓어지길 바라는 마음을 담아 적은 예제이다. 기획자와 디자이너 분들이여, 이제는 맘편히 외쳐보아라.</p>
<blockquote><p>
'개발자야, 이 데이터 스크래이핑하면 되지 않겠니?'
</p></blockquote>
<p><img src="http://images.fotocommunity.com/photos/pets-farm-animals/cats/fat-cat-sleeping-fb8277ad-98ec-4216-943a-0f40e4b24304.jpg" title="Fat Sleeping Cat" width="80%"><br />
<i>CC BY-SA, by Pedro Ivo Jovelli</i></p>
